{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16825 - Learning for 3D Vision\n",
    "## Homework 1 - vinayakp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('C:/Users/VinayakKP/Documents/Spring 25/Learning_For_3D_Vision/Homework/Homework_1/assignment1/starter') \n",
    "import torch\n",
    "import pytorch3d\n",
    "from pytorch3d.structures import Meshes\n",
    "import pytorch3d.renderer as rdr\n",
    "from pytorch3d.io import load_objs_as_meshes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from tqdm.notebook import tqdm\n",
    "import camera_transforms\n",
    "import dolly_zoom\n",
    "import render_generic\n",
    "import render_mesh\n",
    "import utils\n",
    "from IPython.display import Image\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Practicing with Cameras:\n",
    "### 1.1. 360-degree Renders (5 points):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89eb8416e1ea45e1aadec415f6ead4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_mesh_renderer(image_size=512):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    R, T = rdr.look_at_view_transform(2.7, 0, 0)\n",
    "    cameras = rdr.FoVPerspectiveCameras(device=device, R=R, T=T)\n",
    "    \n",
    "    raster_set = rdr.RasterizationSettings(\n",
    "        image_size=image_size, \n",
    "        blur_radius=0.0, \n",
    "        faces_per_pixel=1\n",
    "    )\n",
    "    \n",
    "    lights = rdr.PointLights(device=device, location=[[0.0, 0.0, -3.0]])\n",
    "    \n",
    "    render = rdr.MeshRenderer(\n",
    "        rasterizer=rdr.MeshRasterizer(\n",
    "            cameras=cameras, \n",
    "            raster_settings=raster_set\n",
    "        ),\n",
    "        shader=rdr.HardPhongShader(\n",
    "            device=device, \n",
    "            cameras=cameras,\n",
    "            lights=lights\n",
    "        )\n",
    "    )\n",
    "    return render\n",
    "\n",
    "def render_360_degree_mesh(mesh, device, image_size=512, num_views=72, distance=2.75, elevation=30):\n",
    "    renderer = utils.get_mesh_renderer(image_size=image_size)\n",
    "    angles = torch.linspace(-180, 180, num_views)\n",
    "    lights = rdr.PointLights(location=[[0, 0, -3]], device=device)\n",
    "    images = []\n",
    "    \n",
    "    for angle in tqdm(angles):\n",
    "        R, T = rdr.look_at_view_transform(dist=distance, elev=elevation, azim=angle)\n",
    "        cameras = rdr.FoVPerspectiveCameras(R=R, T=T, device=device)\n",
    "        \n",
    "        render = renderer(mesh, cameras=cameras, lights=lights)\n",
    "        image = render[0, ..., :3].cpu().numpy()\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        images.append(image)\n",
    "    \n",
    "    return images\n",
    "   \n",
    "def save_gif(images, output_path, fps=24):\n",
    "    duration = 1000 // fps\n",
    "    imageio.mimsave(\n",
    "        output_path,\n",
    "        images,\n",
    "        duration=duration,\n",
    "        loop=0\n",
    "    )\n",
    "    \n",
    "obj_filename = \"../data/cow.obj\"\n",
    "mesh = load_objs_as_meshes([obj_filename], device=device)\n",
    "\n",
    "render_img = render_360_degree_mesh(\n",
    "    mesh,\n",
    "    device=device,\n",
    "    image_size=512,\n",
    "    num_views=120,\n",
    "    distance=2.7,\n",
    "    elevation=30\n",
    ")\n",
    "\n",
    "save_gif(render_img, 'mesh_360_hardphongshader.gif', fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Re-creating the Dolly Zoom (10 points): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30378068153b4a39ad72790c5deb1bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dolly_zoom.dolly_zoom(\n",
    "        image_size=512,\n",
    "        num_frames=30,\n",
    "        duration=3,\n",
    "        output_file=\"dolly.gif\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Practicing with Meshes:\n",
    "### 2.1. Constructing a Tetrahedron (5 points):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a278c25aa14a4f94fa2701f886a818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_reg_tetrahedron(device, edge_length):\n",
    "    vertices = (edge_length/5)*torch.tensor([\n",
    "        [2.0412, 2.0412, 2.0412],\n",
    "        [-2.0412, -2.0412, 2.0412],\n",
    "        [-2.0412, 2.0412, -2.0412],\n",
    "        [2.0412, -2.0412, -2.0412]\n",
    "     ], dtype=torch.float32, device=device)\n",
    "\n",
    "    faces = torch.tensor([\n",
    "        [0, 1, 2],\n",
    "        [0, 1, 3],\n",
    "        [0, 2, 3],\n",
    "        [1, 2, 3]\n",
    "     ], dtype=torch.int64, device=device)\n",
    "    \n",
    "    color = torch.tensor([0.0, 0.0, 1.0], device=device)\n",
    "    vertex_colors = torch.ones_like(vertices)[None] * color\n",
    "    textures = rdr.TexturesVertex(verts_features=vertex_colors)\n",
    "\n",
    "    mesh = Meshes(\n",
    "      verts=[vertices],\n",
    "      faces=[faces],\n",
    "      textures=textures\n",
    "     )\n",
    "    \n",
    "    return mesh\n",
    "\n",
    "tetra_mesh = make_reg_tetrahedron(\"cuda:0\", 5)\n",
    "\n",
    "rendered_images = render_360_degree_mesh(\n",
    "    tetra_mesh,\n",
    "    device=device,\n",
    "    image_size=512,\n",
    "    num_views=120,\n",
    "    distance=8,  \n",
    "    elevation=30\n",
    ")\n",
    "\n",
    "save_gif(rendered_images, 'tetrahedron_360.gif', fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Constructing a Cube (5 points):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b30beead8d49eda91e2d8b2ac84e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_cube(device, edge_length):\n",
    "    vertices = (edge_length)*torch.tensor([\n",
    "        [-0.5, 0.5, -0.5],\n",
    "        [0.5, 0.5, -0.5],\n",
    "        [0.5, 0.5, 0.5],\n",
    "        [-0.5, 0.5, 0.5],\n",
    "        [0.5, -0.5, -0.5],\n",
    "        [0.5, -0.5, 0.5],\n",
    "        [-0.5, -0.5, 0.5],\n",
    "        [-0.5, -0.5, -0.5]\n",
    "     ], dtype=torch.float32, device=device)\n",
    "\n",
    "    faces = torch.tensor([\n",
    "        [0, 1, 3],\n",
    "        [1, 2, 3],\n",
    "        [1, 2, 5],\n",
    "        [1, 4, 5],\n",
    "        [4, 5, 7],\n",
    "        [5, 6, 7],\n",
    "        [3, 6, 7],\n",
    "        [3, 0, 7],\n",
    "        [2, 6, 3],\n",
    "        [2, 5, 6],\n",
    "        [0, 4, 7],\n",
    "        [0, 1, 4]\n",
    "     ], dtype=torch.int64, device=device)\n",
    "    \n",
    "    color = torch.tensor([0.0, 0.0, 1.0], device=device)\n",
    "    vertex_colors = torch.ones_like(vertices)[None] * color\n",
    "    textures = rdr.TexturesVertex(verts_features=vertex_colors)\n",
    "\n",
    "    mesh = Meshes(\n",
    "      verts=[vertices],\n",
    "      faces=[faces],\n",
    "      textures=textures\n",
    "     )\n",
    "    \n",
    "    return mesh\n",
    "\n",
    "cube_mesh = make_cube(\"cuda:0\", 5)\n",
    "\n",
    "rendered_images = render_360_degree_mesh(\n",
    "    cube_mesh,\n",
    "    device=device,\n",
    "    image_size=512,\n",
    "    num_views=120,\n",
    "    distance=9,  \n",
    "    elevation=30\n",
    ")\n",
    "\n",
    "save_gif(rendered_images, 'cube_360.gif', fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retexturing a Mesh (10 points):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e7d36723414d699b02cb66fa25b1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def apply_color_gradient(mesh, color1, color2, device):\n",
    "    verts = mesh.verts_packed()\n",
    "    \n",
    "    z_coords = verts[:, 2]\n",
    "    \n",
    "    z_min, z_max = z_coords.min(), z_coords.max()\n",
    "    alpha = (z_coords - z_min) / (z_max - z_min)\n",
    "    \n",
    "    alpha = alpha.unsqueeze(-1)\n",
    "    \n",
    "    color1 = torch.tensor(color1, device=device)\n",
    "    color2 = torch.tensor(color2, device=device)\n",
    "    \n",
    "    vertex_colors = alpha * color2 + (1 - alpha) * color1\n",
    "    vertex_colors = vertex_colors.unsqueeze(0)\n",
    "    \n",
    "    textures = rdr.TexturesVertex(vertex_colors)\n",
    "    \n",
    "    color_mesh = Meshes(\n",
    "        verts=mesh.verts_list(),\n",
    "        faces=mesh.faces_list(),\n",
    "        textures=textures\n",
    "    )\n",
    "    \n",
    "    return color_mesh\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "obj_filename = \"../data/cow.obj\"\n",
    "mesh = load_objs_as_meshes([obj_filename], device=device)\n",
    "\n",
    "color1 = [1.0, 0.0, 0.0]  \n",
    "color2 = [0.0, 0.0, 1.0]  \n",
    "\n",
    "colored_mesh = apply_color_gradient(mesh, color1, color2, device)\n",
    "\n",
    "rendered_images = render_360_degree_mesh(\n",
    "    colored_mesh,\n",
    "    device=device,\n",
    "    image_size=512,\n",
    "    num_views=120,\n",
    "    distance=2.7,\n",
    "    elevation=30\n",
    ")\n",
    "\n",
    "save_gif(rendered_images, 'color_gradient_cow_360.gif', fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Camera Transformations (10 points):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VinayakKP\\AppData\\Local\\Temp\\ipykernel_28356\\3654917673.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R_relative = torch.tensor(R_relative).float()\n",
      "C:\\Users\\VinayakKP\\AppData\\Local\\Temp\\ipykernel_28356\\3654917673.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  T_relative = torch.tensor(T_relative).float()\n"
     ]
    }
   ],
   "source": [
    "# I am copying this function and removing the get_device() part here instead of calling it from camera_transforms.py as my device is cuda and the default implementation is giving me some problems\n",
    "\n",
    "def render_textured_cow(\n",
    "    cow_path=\"../data/cow.obj\",\n",
    "    image_size=256,\n",
    "    # default case 0\n",
    "    # R_relative=[[1, 0, 0], [0, 1, 0], [0, 0, 1]],\n",
    "    # T_relative=[0, 0, 0],\n",
    "    # CW 90-degree roation about z_axis case 1\n",
    "    # R_relative=[[0, 1, 0], [-1, 0, 0], [0, 0, 1]],\n",
    "    # T_relative =[0, 0, 0],\n",
    "    # CW 90-degree rotation about y_axis case 2\n",
    "    # R_relative=[[0, 0, 1], [0, 1, 0], [-1, 0, 0]],\n",
    "    # T_relative=[-3, 0, 3],\n",
    "    # Zoom out (z direction) case 3\n",
    "    # R_relative=[[1, 0, 0], [0, 1, 0], [0, 0, 1]],\n",
    "    # T_relative=[0, 0, 3],\n",
    "    # Translation in x-y plane case 4\n",
    "    R_relative=[[1, 0, 0], [0, 1, 0], [0, 0, 1]],\n",
    "    T_relative=[0.5, -0.5, 0],\n",
    "    device=device,\n",
    "):\n",
    "    meshes = pytorch3d.io.load_objs_as_meshes([cow_path]).to(device)\n",
    "    R_relative = torch.tensor(R_relative).float()\n",
    "    T_relative = torch.tensor(T_relative).float()\n",
    "    R = R_relative @ torch.tensor([[1.0, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    T = R_relative @ torch.tensor([0.0, 0, 3]) + T_relative\n",
    "    renderer = get_mesh_renderer(image_size=256)\n",
    "    cameras = pytorch3d.renderer.FoVPerspectiveCameras(\n",
    "        R=R.unsqueeze(0), T=T.unsqueeze(0), device=device,\n",
    "    )\n",
    "    lights = pytorch3d.renderer.PointLights(location=[[0, 0.0, -3.0]], device=device,)\n",
    "    rend = renderer(meshes, cameras=cameras, lights=lights)\n",
    "    return rend[0, ..., :3].cpu().numpy()\n",
    "\n",
    "R_relative1 = torch.tensor([[0, 1, 0], [-1, 0, 0], [0, 0, 1]])\n",
    "T_relative1 = torch.tensor([0, 0, 0])\n",
    "Img1 = render_textured_cow(R_relative=R_relative1, T_relative=T_relative1)\n",
    "plt.imsave(\"textured_cow1.jpg\", Img1)\n",
    "\n",
    "R_relative2 = torch.tensor([[0, 0, 1], [0, 1, 0], [-1, 0, 0]])\n",
    "T_relative2 = torch.tensor([-3, 0, 3])\n",
    "Img2 = render_textured_cow(R_relative=R_relative2, T_relative=T_relative2)\n",
    "plt.imsave(\"textured_cow2.jpg\", Img2)\n",
    "\n",
    "R_relative3 = torch.tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "T_relative3 = torch.tensor([0, 0, 3])\n",
    "Img3 = render_textured_cow(R_relative=R_relative3, T_relative=T_relative3)\n",
    "plt.imsave(\"textured_cow3.jpg\", Img3)\n",
    "\n",
    "R_relative4 = torch.tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "T_relative4 = torch.tensor([0.5, -0.5, 0])\n",
    "Img4 = render_textured_cow(R_relative=R_relative4, T_relative=T_relative4)\n",
    "plt.imsave(\"textured_cow4.jpg\", Img4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Rendering Generic 3D Representations:\n",
    "\n",
    "### 5.1. Rendering Point Clouds from RGB-D Images (10 points):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = render_generic.load_rgbd_data(path=\"../data/rgbd_data.pkl\")\n",
    "\n",
    "points1, colors1 = utils.unproject_depth_image(torch.tensor(data[\"rgb1\"]), \n",
    "                                              torch.tensor(data[\"mask1\"]),\n",
    "                                              torch.tensor(data[\"depth1\"]),\n",
    "                                              data[\"cameras1\"])\n",
    "\n",
    "pc1 = pytorch3d.structures.Pointclouds(points=points1.unsqueeze(0), features=colors1.unsqueeze(0)).to(device)\n",
    "num_views=120\n",
    "angles = torch.linspace(-180, 180, num_views)\n",
    "image_size = 256\n",
    "\n",
    "R, T = rdr.look_at_view_transform(dist = 10, elev = 0, azim = angles)\n",
    "\n",
    "R = torch.tensor([[-1, 0, 0], [0, -1, 0], [0, 0, 1]]).float()@R\n",
    "\n",
    "cameras = rdr.FoVPerspectiveCameras(R=R, T=T, device=device)\n",
    "lights = rdr.PointLights(location=[[0, 0, -3]], device=device)\n",
    "renderer = utils.get_points_renderer(image_size=image_size, device=device)\n",
    "\n",
    "images = renderer(pc1.extend(num_views), cameras = cameras, lights = lights)\n",
    "images = images.cpu().numpy()[..., :3] \n",
    "images = (images * 255).clip(0, 255).astype(np.uint8)\n",
    "imageio.mimsave(\"pc1.gif\", images, fps=30, loop = 0)\n",
    "\n",
    "points2, colors2 = utils.unproject_depth_image(torch.tensor(data[\"rgb2\"]), \n",
    "                                              torch.tensor(data[\"mask2\"]),\n",
    "                                              torch.tensor(data[\"depth2\"]),\n",
    "                                              data[\"cameras2\"])\n",
    "\n",
    "pc2 = pytorch3d.structures.Pointclouds(points=points2.unsqueeze(0), features=colors2.unsqueeze(0)).to(device)\n",
    "\n",
    "images = renderer(pc2.extend(num_views), cameras = cameras, lights = lights)\n",
    "images = images.cpu().numpy()[..., :3] \n",
    "images = (images * 255).clip(0, 255).astype(np.uint8)\n",
    "imageio.mimsave(\"pc2.gif\", images, fps=30, loop = 0)\n",
    "\n",
    "pc3 = pytorch3d.structures.Pointclouds(points=torch.cat((points1,points2), 0).unsqueeze(0), features=torch.cat((colors1,colors2), 0).unsqueeze(0),).to(device)\n",
    "\n",
    "images = renderer(pc3.extend(num_views), cameras= cameras, lights= lights)\n",
    "images = images.cpu().numpy()[..., :3] \n",
    "images = (images * 255).clip(0, 255).astype(np.uint8)\n",
    "imageio.mimsave(\"pc3.gif\", images, fps=30, loop = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Parametric Functions (10 + 5 points):\n",
    "\n",
    "Part 1: Torus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points_renderer(\n",
    "    image_size=512, radius=0.01, background_color=(1, 1, 1), device=None\n",
    "):\n",
    "    if device is None:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda:0\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "    raster_settings = rdr.PointsRasterizationSettings(image_size=image_size, radius=radius,)\n",
    "    renderer = rdr.PointsRenderer(\n",
    "        rasterizer= rdr.PointsRasterizer(raster_settings=raster_settings),\n",
    "        compositor= rdr.AlphaCompositor(background_color=background_color),\n",
    "    )\n",
    "    return renderer\n",
    "    \n",
    "def get_torus_points(num_samples, c=3, a=2):\n",
    "    u = torch.linspace(0, 2 * torch.pi, num_samples)\n",
    "    v = torch.linspace(0, 2 * torch.pi, num_samples)\n",
    "    u, v = torch.meshgrid(u, v)\n",
    "    \n",
    "    x = (c + a * torch.cos(v)) * torch.cos(u)\n",
    "    y = (c + a * torch.cos(v)) * torch.sin(u)\n",
    "    z = a * torch.sin(v)\n",
    "    \n",
    "    points = torch.stack((x.flatten(), y.flatten(), z.flatten()), dim=1).unsqueeze(0)\n",
    "    return points\n",
    "\n",
    "def parametric_torus_colors(num_samples):\n",
    "    u = torch.linspace(0, 2 * torch.pi, num_samples)\n",
    "    v = torch.linspace(0, 2 * torch.pi, num_samples)\n",
    "    u, v = torch.meshgrid(u, v)\n",
    "    \n",
    "    colors_r = torch.cos(u).flatten()\n",
    "    colors_b = torch.sin(v).flatten()\n",
    "    colors_g = torch.zeros_like(colors_r)\n",
    "    \n",
    "    colors = torch.stack([colors_r, colors_g, colors_b], dim=1)\n",
    "    colors = (colors + 1) / 2\n",
    "    colors = colors.unsqueeze(0)\n",
    "    return colors\n",
    "\n",
    "num_samples = 200\n",
    "torus_pts = get_torus_points(num_samples = num_samples).to(device)\n",
    "torus_color = parametric_torus_colors(num_samples = num_samples).to(device)\n",
    "\n",
    "pc_torus = pytorch3d.structures.Pointclouds(points = torus_pts, features = torus_color).to(device)\n",
    "R, T = rdr.look_at_view_transform(dist=10, elev=0, azim = angles)\n",
    "renderer = get_points_renderer(image_size=image_size)\n",
    "images = renderer(pc_torus.extend(num_views), cameras=cameras)\n",
    "images = images.cpu().numpy()[..., :3]\n",
    "images = (images * 255).clip(0, 255).astype(np.uint8)\n",
    "imageio.mimsave(\"torus360.gif\", images, fps=30, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Square Torus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_square_torus_points(num_samples, R=2, a=1, n=8):\n",
    "    u = torch.linspace(0, 2 * torch.pi, num_samples)\n",
    "    v = torch.linspace(0, 2 * torch.pi, num_samples)\n",
    "    u, v = torch.meshgrid(u, v)\n",
    "    \n",
    "    r = (torch.abs(torch.cos(v))**n + torch.abs(torch.sin(v))**n)**(-1/n)\n",
    "    \n",
    "    x = (R + a * r * torch.cos(v)) * torch.cos(u)\n",
    "    y = (R + a * r * torch.sin(v)) * torch.sin(u)\n",
    "    z = a * r * torch.sin(v)\n",
    "    \n",
    "    points = torch.stack([x.flatten(), y.flatten(), z.flatten()], dim=1).unsqueeze(0)\n",
    "    return points\n",
    "\n",
    "def color_square_torus(num_samples):\n",
    "    u = torch.linspace(0, 2 *torch.pi, num_samples)\n",
    "    v = torch.linspace(0, 2 *torch.pi, num_samples)\n",
    "    u, v = torch.meshgrid(u, v)\n",
    "    \n",
    "    colors_r = torch.abs(torch.cos(v)).flatten()\n",
    "    colors_g = torch.abs(torch.sin(u)).flatten()\n",
    "    colors_b = torch.abs(torch.sin(v + u)).flatten()\n",
    "    \n",
    "    colors =torch.stack([colors_r, colors_g, colors_b], dim=1).unsqueeze(0)\n",
    "    return colors\n",
    "\n",
    "num_samples = 200\n",
    "sq_torus_pts = get_square_torus_points(num_samples = num_samples).to(device)\n",
    "sq_torus_colors = color_square_torus(num_samples = num_samples).to(device)\n",
    "\n",
    "pc_sq_torus = pytorch3d.structures.Pointclouds(points = sq_torus_pts, features = sq_torus_colors).to(device)\n",
    "R, T = rdr.look_at_view_transform(dist=10, elev=0, azim = angles)\n",
    "renderer = get_points_renderer(image_size=image_size)\n",
    "images = renderer(pc_sq_torus.extend(num_views), cameras=cameras)\n",
    "images = images.cpu().numpy()[..., :3]\n",
    "images = (images * 255).clip(0, 255).astype(np.uint8)\n",
    "imageio.mimsave(\"squaretorus360.gif\", images, fps=30, loop=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Implicit Surfaces (15 + 5 points):\n",
    "\n",
    "Part 1: Torus Mesh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mcubes\n",
    "\n",
    "def torus_implicit_fxn(grid_size=128, R=1.0, r=0.4):\n",
    "    x = torch.linspace(-2, 2, grid_size)\n",
    "    y = torch.linspace(-2, 2, grid_size)\n",
    "    z = torch.linspace(-2, 2, grid_size)\n",
    "    \n",
    "    X, Y, Z = torch.meshgrid(x, y, z, indexing='ij')\n",
    "    squared_term = (R - torch.sqrt(X**2 + Y**2))**2\n",
    "    F = squared_term + Z**2 - r**2\n",
    "    volume = F.numpy()\n",
    "    vertices, faces = mcubes.marching_cubes(volume, 0)\n",
    "    vertices = vertices / grid_size * 4 - 2\n",
    "    vertices = torch.from_numpy(vertices).float()\n",
    "    faces = torch.from_numpy(faces).long()\n",
    "    return vertices, faces\n",
    "\n",
    "grid_size = 128\n",
    "vertices, faces = torus_implicit_fxn(grid_size=grid_size)\n",
    "textures = rdr.TexturesVertex(vertices.unsqueeze(0))\n",
    "mesh = pytorch3d.structures.Meshes([vertices], [faces], textures=textures).to(device)\n",
    "\n",
    "renderer = get_mesh_renderer(image_size=image_size)\n",
    "lights = rdr.PointLights(location=[[0, 0.0, -4.0]], device=device)   \n",
    "R, T = rdr.look_at_view_transform(dist=5, elev=0, azim = angles)\n",
    "cameras = rdr.FoVPerspectiveCameras(R=R, T=T, device=device)\n",
    "\n",
    "images = renderer(mesh.extend(num_views), cameras=cameras, lights = lights)\n",
    "images = images.cpu().numpy()[..., :3]\n",
    "images = (images * 255).clip(0, 255).astype(np.uint8)\n",
    "imageio.mimsave(\"torus_fxn.gif\", images, fps=30, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Double-Bubble Surface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_bubble(grid_size=128):\n",
    "    x = torch.linspace(-2, 2, grid_size)\n",
    "    y = torch.linspace(-2, 2, grid_size)\n",
    "    z = torch.linspace(-2, 2, grid_size)\n",
    "    \n",
    "    X, Y, Z = torch.meshgrid(x, y, z, indexing='ij')\n",
    "    \n",
    "    sphere1 = (X + 0.5)**2 + Y**2 + Z**2 - 1\n",
    "    sphere2 = (X - 0.5)**2 + Y**2 + Z**2 - 1\n",
    "    \n",
    "    F = torch.minimum(sphere1, sphere2)\n",
    "    \n",
    "    volume = F.numpy()\n",
    "    vertices, faces = mcubes.marching_cubes(volume, 0)\n",
    "    vertices = vertices / grid_size * 4 - 2\n",
    "    vertices = torch.from_numpy(vertices).float()\n",
    "    faces = torch.from_numpy(faces).long()\n",
    "    return vertices, faces\n",
    "\n",
    "grid_size = 128\n",
    "vertices, faces = double_bubble(grid_size=grid_size)\n",
    "textures = rdr.TexturesVertex(vertices.unsqueeze(0))\n",
    "mesh = Meshes([vertices], [faces], textures=textures).to(device)\n",
    "\n",
    "renderer = get_mesh_renderer(image_size=image_size)\n",
    "lights = rdr.PointLights(location=[[0, 0.0, -4.0]], device=device)   \n",
    "R, T = rdr.look_at_view_transform(dist=5, elev=0, azim = angles)\n",
    "cameras = rdr.FoVPerspectiveCameras(R=R, T=T, device=device)\n",
    "\n",
    "\n",
    "images = renderer(mesh.extend(num_views), cameras=cameras, lights = lights)\n",
    "images = images.cpu().numpy()[..., :3]\n",
    "images = (images * 255).clip(0, 255).astype(np.uint8)\n",
    "imageio.mimsave(\"double_bubble_fxn.gif\", images, fps=30, loop=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Do Something Fun (10 points):\n",
    "\n",
    "### Morphing between sphere and torus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphing_shapes(t, grid_size=128):\n",
    "    x = torch.linspace(-2, 2, grid_size)\n",
    "    y = torch.linspace(-2, 2, grid_size)\n",
    "    z = torch.linspace(-2, 2, grid_size)\n",
    "    \n",
    "    X, Y, Z = torch.meshgrid(x, y, z, indexing='ij')\n",
    "    \n",
    "    sphere = X**2 + Y**2 + Z**2 - 1\n",
    "    \n",
    "    R = 1.0\n",
    "    r = 0.4\n",
    "    torus = (R - torch.sqrt(X**2 + Y**2))**2 + Z**2 - r**2\n",
    "    \n",
    "    F = (1-t) * sphere + t * torus\n",
    "    \n",
    "    volume = F.numpy()\n",
    "    vertices, faces = mcubes.marching_cubes(volume, 0)\n",
    "    vertices = vertices / grid_size * 4 - 2\n",
    "    \n",
    "    return torch.from_numpy(vertices).float(), torch.from_numpy(faces).long()\n",
    "\n",
    "grid_size = 128\n",
    "vertices, faces = morphing_shapes(grid_size=grid_size, t = 0.5)\n",
    "textures = rdr.TexturesVertex(verts_features=torch.ones_like(vertices).unsqueeze(0))\n",
    "mesh = Meshes([vertices], [faces], textures=textures).to(device)\n",
    "\n",
    "renderer = get_mesh_renderer(image_size=image_size)\n",
    "lights = rdr.PointLights(location=[[0, 0.0, -4.0]], device=device)\n",
    "R, T = rdr.look_at_view_transform(dist=5, elev=0, azim = angles)\n",
    "cameras = rdr.FoVPerspectiveCameras(R=R, T=T, device=device)\n",
    "\n",
    "images = renderer(mesh.extend(num_views), cameras=cameras, lights = lights)\n",
    "images = images.cpu().numpy()[..., :3]\n",
    "images = (images * 255).clip(0, 255).astype(np.uint8)\n",
    "imageio.mimsave(\"morphing_shapes.gif\", images, fps=15, loop=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
